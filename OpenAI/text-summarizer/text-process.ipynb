{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import tiktoken\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.base_url = os.environ.get(\"OPENAI_API_BASE\")\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "openai.api_version = \"2023-05-15\"\n",
    "\n",
    "CHAT_MODEL =  os.environ.get(\"OPENAI_CHAT_DEPLOYMENT_NAME\") \n",
    "encoding = tiktoken.get_encoding('cl100k_base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Define the path to the large text file\n",
    "file_path = 'script.txt'\n",
    "\n",
    "# Open the file and read its content\n",
    "with open(file_path, 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Split the text into sentences\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "# Group sentences into chunks of approximately 5000 tokens\n",
    "chunks = []\n",
    "current_chunk = \"\"\n",
    "for sentence in sentences:\n",
    "    if len(current_chunk + sentence) <= 5000:\n",
    "        current_chunk += sentence\n",
    "    else:\n",
    "        chunks.append(current_chunk)\n",
    "        current_chunk = sentence\n",
    "chunks.append(current_chunk)  # append the last chunk\n",
    "\n",
    "# Create a new directory named 'chunks' if it doesn't exist\n",
    "Path('chunks').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Delete all files in the 'chunks' directory\n",
    "folder_path = 'chunks'\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        os.remove(file_path)\n",
    "\n",
    "# Save each chunk into a separate file in the 'chunks' directory\n",
    "for i, chunk in enumerate(chunks):\n",
    "    with open(f'chunks/chunk_{i}.txt', 'w') as file:\n",
    "        file.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key = os.getenv(\"OPENAI_API_KEY\"),  \n",
    "  api_version = \"2023-05-15\",\n",
    "  azure_endpoint = os.getenv(\"OPENAI_API_BASE\")\n",
    ")\n",
    "\n",
    "def get_completion(prompt, model=CHAT_MODEL):\n",
    "    response = client.chat.completions.create(\n",
    "        temperature=0, \n",
    "        model=CHAT_MODEL, \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant with expertise in reading, writing and notetaking.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptPreFix = \"Read the transcript below. Summarize the highlights about OpenAI, its history and relevant informtion in a bullet list. Keep only the highlights. I will use these as talking points when I present about OpenAI. Keep all text concise. Provide chronological sense.\"\n",
    "\n",
    "os.makedirs('chunk-summary', exist_ok=True)\n",
    "folder_path = 'chunks'\n",
    "file_count = len(os.listdir(folder_path)) \n",
    "\n",
    "# Read each chunk and call the get_completion function\n",
    "for i in range(file_count):\n",
    "    with open(f'chunks/chunk_{i}.txt', 'r') as file:\n",
    "        chunk_content = file.read()\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "        {promptPreFix}\n",
    "        ---\n",
    "        {chunk_content}\n",
    "        ---\n",
    "        \"\"\"\n",
    "    \n",
    "    # Call the get_completion function and get the response\n",
    "    response = get_completion(prompt)\n",
    "    \n",
    "    # Save the response to a separate file in the 'chunk-summary' directory\n",
    "    with open(f'chunk-summary/chunk_{i}_summary.txt', 'w') as file:\n",
    "        file.write(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create a new directory named 'combined' if it doesn't exist\n",
    "combined_folder_path = 'combined'\n",
    "os.makedirs(combined_folder_path, exist_ok=True)\n",
    "\n",
    "# Get the list of chunk summary files\n",
    "chunk_summary_folder_path = 'chunk-summary'\n",
    "chunk_summary_files = os.listdir(chunk_summary_folder_path)\n",
    "\n",
    "# Combine the content of all chunk summary files into a single text file\n",
    "combined_text = \"\"\n",
    "for file_name in chunk_summary_files:\n",
    "    file_path = os.path.join(chunk_summary_folder_path, file_name)\n",
    "    with open(file_path, 'r') as file:\n",
    "        chunk_summary = file.read()\n",
    "        combined_text += chunk_summary + \"\\n\"\n",
    "\n",
    "# Save the combined text into a single file in the 'combined' directory\n",
    "combined_file_path = os.path.join(combined_folder_path, 'combined_summary.txt')\n",
    "with open(combined_file_path, 'w') as file:\n",
    "    file.write(combined_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
