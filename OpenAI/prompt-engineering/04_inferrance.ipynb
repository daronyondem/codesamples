{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "CHAT_MODEL =  os.environ.get(\"OPENAI_CHAT_DEPLOYMENT_NAME\") \n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key = os.getenv(\"OPENAI_API_KEY\"),  \n",
    "  api_version = \"2023-05-15\",\n",
    "  azure_endpoint = os.getenv(\"OPENAI_API_BASE\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=CHAT_MODEL):\n",
    "    response = client.chat.completions.create(\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "        model=\"drn-chat-dev2\", # This is currently gpt-35-turbo\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sampletext = f\"\"\"I recently purchased the Stellaris Luminary LED Light Bulb and I must say, I'm completely blown away by its performance. This isn't your ordinary LED light bulb, it's a game changer!\n",
    "\n",
    "First of all, the brightness level this bulb produces is simply unparalleled. Whether you're using it for your reading room or simply as an overhead light in the living room, it illuminates the space with an impressive, crisp, and clear light. It's as if daylight has been captured and put inside a bulb! The adjustable brightness feature is also a nifty addition, allowing you to set the ambiance according to your mood.\n",
    "\n",
    "The energy efficiency of the Stellaris Luminary LED Light Bulb deserves a special mention. Despite its high brightness, it consumes significantly less power compared to traditional bulbs. This is a big plus for anyone looking to cut down on energy costs. Our monthly electricity bill has already shown a noticeable decrease, making this bulb a worthy investment.\n",
    "\n",
    "In terms of lifespan, the Stellaris Luminary outperforms every other light bulb I've ever used. It's been three months now and it's still shining as brightly as the day it was installed. The manufacturer promises a lifespan of 25,000 hours, and judging by its performance thus far, I have no reason to doubt this claim.\n",
    "\n",
    "The design of the bulb is sleek and modern, fitting in well with our home's contemporary decor. It's easy to install, and the customer service from Stellaris was top-notch when I had a query about the product.\n",
    "\n",
    "In conclusion, the Stellaris Luminary LED Light Bulb has exceeded my expectations in every aspect. It's bright, energy-efficient, long-lasting, and well-designed. It's more than just a light bulb, it's a smart investment for any household. I would highly recommend this product to anyone in search of a superior lighting solution.\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "What is the sentiment of the following product review, \n",
    "which is put between two lines of dashes?\n",
    "Give me your answer as a word.\n",
    "---\n",
    "{sampletext}\n",
    "---\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Give me a list of emotions that are expressed in the following product review,\n",
    "which is put between two lines of dashes?\n",
    "Provide the list in a JSON array.\n",
    "---\n",
    "{sampletext}\n",
    "---\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity and Keyword Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text which is put between two lines of dashes: \n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "Provide the list in a JSON array.\n",
    "---\n",
    "{sampletext}\n",
    "---\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferring Specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text which is put between two lines of dashes: \n",
    "- Features of the product resulting in positive sentiment\n",
    "- Aspects of the product resulting in negative sentiment\n",
    "\n",
    "Reword all features and aspects in the form of a product specification.\n",
    "\n",
    "Provide the list of specifications (Not features) under reach sentiment.\n",
    "---\n",
    "{sampletext}\n",
    "---\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intent Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sampletext = f\"\"\"Can I get a ticker to Paris from Istanbul airport for tomorrow 8AM?\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Consider the list of actions below\n",
    "- Book a flight\n",
    "- Rent a car\n",
    "- Buy a bus ticket\n",
    "\n",
    "Based on the following text given between two lines of ashes\n",
    "- which action is the user trying to perform?\n",
    "- extract keywords from the text that are relevant to the action\n",
    "- if found give a destination for the action\n",
    "- if found give a time for the action\n",
    "- if found give a date for the action. Today is Sep 8. 2023.\n",
    "- if found give a source for the action\n",
    "\n",
    "Provide your response in the form of a JSON object.\n",
    "\n",
    "---\n",
    "{sampletext}\n",
    "---\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-qna-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4ee1bbf3137c7ea9420c4fd488a55642063e5739fe2a7286130d9ba47405b69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
