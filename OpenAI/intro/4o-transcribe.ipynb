{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY_NON_AZURE\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "import math\n",
    "\n",
    "input_audio = 'audiofile.m4a'\n",
    "chunk_duration_sec = 300  # 5 minutes per chunk.\n",
    "# Shorter chunks (e.g., 5â€“10 minutes) help the transcription model clearly recognize context. Long chunks can lose context and cause the model to misinterpret segments.\n",
    "# OpenAI charges for audio transcription for the length of audio processed, not per number of API calls. \n",
    "# Splitting the same audio into shorter segments does not affect total cost since the total length of audio remains constant.\n",
    "# Shorter chunks improve accuracy without increasing your total transcription cost.\n",
    "output_dir = 'chunks'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create directory for chunks\n",
    "os.makedirs('chunks', exist_ok=True)\n",
    "\n",
    "# Get total duration using ffmpeg\n",
    "def get_audio_duration(filename):\n",
    "    probe = ffmpeg.probe(filename)\n",
    "    return float(probe['format']['duration'])\n",
    "\n",
    "audio_length = get_audio_duration(input_audio)\n",
    "num_chunks = math.ceil(audio_length / chunk_duration_sec)\n",
    "\n",
    "transcriptions = []\n",
    "\n",
    "# Replace 'en' with your language code ('tr' for Turkish, 'fr' for French, etc.)\n",
    "# Language detection usually works well, but better to specify it manually for increased accuracy\n",
    "target_language = 'tr'\n",
    "\n",
    "for i in range(num_chunks):\n",
    "    start_time = i * chunk_duration_sec\n",
    "    chunk_filename = os.path.join(output_dir, f'chunk_{i+1}.mp3')\n",
    "    \n",
    "     # Remove silence at start of each chunk\n",
    "    ffmpeg.input(input_audio, ss=start_time, t=chunk_duration_sec)\\\n",
    "        .filter('silenceremove', start_periods=1, start_duration=0.5, start_threshold='-50dB')\\\n",
    "        .output(chunk_filename, audio_bitrate='128k')\\\n",
    "        .run(overwrite_output=True)\n",
    "\n",
    "    print(f'Transcribing chunk {i+1}/{num_chunks}...')\n",
    "\n",
    "    with open(chunk_filename, 'rb') as audio_file:\n",
    "        transcription = client.audio.transcriptions.create(\n",
    "            model='gpt-4o-transcribe',  # replace with 'gpt-4o-transcribe' if supported\n",
    "            file=audio_file,\n",
    "            language=target_language  # explicitly specify language\n",
    "        )\n",
    "\n",
    "    transcriptions.append(transcription.text)\n",
    "\n",
    "# Save combined transcription\n",
    "output_transcription_file = 'full_transcription.txt'\n",
    "with open(output_transcription_file, 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n\\n'.join(transcriptions))\n",
    "\n",
    "print(f'Full transcription saved to {output_transcription_file}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4o-transcribe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
