{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Text Processing and Retrieval-Augmented Generation with Azure AI Search and C# in .NET\n",
    "\n",
    "This Jupyter notebook offers a concise exploration into advanced text processing and retrieval-augmented generation (RAG) using C# and Azure AI Search. Key highlights include:\n",
    "\n",
    "- **Text Chunking**: Explains breaking down large texts into smaller chunks for efficient language model processing.\n",
    "- **Text Embeddings Creation**: Guides on generating text embeddings using Azure OpenAI service.\n",
    "- **Vector Index Setup on Azure AI Search**: Instructs on establishing a vector index on Azure AI Search for enhanced search capabilities.\n",
    "- **Uploading Embeddings**: Covers the process of uploading text embeddings to Azure AI Search.\n",
    "- **Vector Similarity Searches**: Showcases conducting searches using vector similarity in Azure AI Search.\n",
    "- **Retrieval-Augmented Generation with GPT**: Demonstrates enhancing GPT model responses using external data and RAG techniques.\n",
    "\n",
    "This notebook acts as a hands-on tutorial for individuals interested in implementing Retrieval-Augmented Generation (RAG) with Large Language Models (LLMs) within a .NET framework environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Create a .env file with the below structure. The values used in the sample below are for demonstration purposes only. Please replace them with your own values.\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=\"9f2b47e4c8a5461db2e4f3a1b517f2cd\"\n",
    "OPENAI_API_BASE=\"https://openai-custom-url.openai.azure.com\"\n",
    "OPENAI_API_VERSION=\"2022-12-01\"\n",
    "OPENAI_API_TYPE=\"azure\"\n",
    "OPENAI_CHAT_DEPLOYMENT_NAME=\"chat-deployment-example\"\n",
    "OPENAI_CHAT_API_VERSION=\"2023-03-15-preview\"\n",
    "AZURE_SEARCH_SERVICE_ENDPOINT = \"https://examplesearchservice.search.windows.net\"\n",
    "AZURE_SEARCH_ADMIN_KEY = \"3pR4x7q9Yt0HlZ5m8nB2UaX1wQ6cD8eFgHiJkLmNoPqRsTcUvWZg\"\n",
    "```\n",
    "\n",
    "Install and configure Polyglot Notebooks extension for VSCVode. This extension allows you to run C# code in Jupyter notebooks. For more information, please visit [Polyglot Notebooks](https://marketplace.visualstudio.com/items?itemName=donjayamanne.polyglot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using System.IO;\n",
    "using System.Collections.Generic;\n",
    "\n",
    "// Function to read environment variables from a .env file.\n",
    "Dictionary<string, string> ReadEnvFile(string filePath)\n",
    "{\n",
    "    var dict = new Dictionary<string, string>();\n",
    "    foreach (var line in File.ReadAllLines(filePath))\n",
    "    {\n",
    "        var parts = line.Split('=', 2);\n",
    "        if (parts.Length == 2)\n",
    "        {\n",
    "            var key = parts[0].Trim();\n",
    "            var value = parts[1].Trim().Trim('\"'); // Remove any double quotes\n",
    "            dict[key] = value;\n",
    "        }\n",
    "    }\n",
    "    return dict;\n",
    "}\n",
    "\n",
    "// Read the environment variables from the .env file\n",
    "var envVars = ReadEnvFile(\".env\");\n",
    "\n",
    "// Retrieve the OpenAI API base URL and key from the environment variables\n",
    "string endpoint = envVars[\"OPENAI_API_BASE\"];\n",
    "string apiKey = envVars[\"OPENAI_API_KEY\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Chunking with Semantic Kernal\n",
    "\n",
    "Text chunking in the context of Large Language Models (LLM) and Retrieval-Augmented Generation (RAG) implementations is essentially the process of breaking down a large piece of text into smaller, manageable parts or \"chunks.\" This is done to make the processing and understanding of the text more efficient for the model. Crucially, this process is intertwined with the context window size of the model, which defines the amount of text the model can consider at any one time. By dividing text into chunks that fit within this window, the model can process and comprehend each segment effectively without losing vital information that might be omitted if the text exceeds the window size. Further research into various chunking strategies could be beneficial, especially in ensuring that these chunks are structured in a way that preserves the meaningfulness and coherence of the text. This would enhance the model's ability to interpret and generate more contextually rich and accurate responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget: Microsoft.SemanticKernel, 1.0.1\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we're loading a local text file named \"azure-functions-June-2023-Updates.txt,\" which serves as an example of an external data source. We're dividing the content of this file into numerous segments, with each line containing 13 tokens and each paragraph comprising 250 tokens. It's advisable to experiment with these parameters to determine the optimal settings for your specific use cases and data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.SemanticKernel.Text;\n",
    "\n",
    "// Read the entire content of the RAG update sample file \n",
    "string filePath = \"azure-functions-June-2023-Updates.txt\";\n",
    "string updateText = await File.ReadAllTextAsync(filePath);\n",
    "\n",
    "// Disable warning SKEXP0055 \n",
    "// 'Microsoft.SemanticKernel.Text.TextChunker' is for evaluation purposes only \n",
    "// and is subject to change or removal in future updates.\n",
    "#pragma warning disable SKEXP0055 \n",
    "\n",
    "// Split the update text into paragraphs\n",
    "// MaxTokensPerLine is set to 128 and MaxTokensPerParagraph is set to 250\n",
    "List<string> paragraphs = TextChunker.SplitPlainTextParagraphs(\n",
    "    TextChunker.SplitPlainTextLines(updateText, 128), //MaxTokensPerLine\n",
    "    250 //MaxTokensPerParagraph\n",
    ");\n",
    "\n",
    "// Re-enable warning SKEXP0055\n",
    "#pragma warning restore SKEXP0055 \n",
    "\n",
    "Console.WriteLine($\"Number of chunks: {paragraphs.Count}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Embedding\n",
    "\n",
    "Embeddings are numerical vectors or arrays that encapsulate the meaning and context of tokens processed and generated by the model. These embeddings originate from the model's parameters or weights. Once created, they are stored in a vector database. This storage allows for advanced semantic and vector searches, facilitating the retrieval of information closely related to a given prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Import required packages.\n",
    "#r \"nuget: Azure.AI.OpenAI, 1.0.0-beta.12\" \n",
    "#r \"nuget: Azure\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we are creating embeddings for each text chunk we have previously segmented. Both the embeddings and their corresponding original text segments are being compiled into an in-memory collection of documents. This compiled list will subsequently be stored in a vector database in the following step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using Azure;\n",
    "using Azure.AI.OpenAI;\n",
    "using System.Linq;\n",
    "\n",
    "AzureKeyCredential credentials = new (apiKey);\n",
    "OpenAIClient openAIClient = new (new Uri(endpoint), credentials);\n",
    "\n",
    "// Initialize a list to hold the embedding documents\n",
    "List<Dictionary<string, object>> inputDocuments = new();\n",
    "\n",
    "// Iterate over each paragraph in the chunks collection\n",
    "foreach (var paragraph in paragraphs)\n",
    "{\n",
    "    // Initialize a new dictionary to hold the current embedding document\n",
    "    Dictionary<string, object> currentDocument = new();\n",
    "\n",
    "    EmbeddingsOptions embeddingOptions = new()\n",
    "    {\n",
    "        // Specify the deployment name for the embedding model\n",
    "        DeploymentName = \"text-embedding-ada-002\",\n",
    "        Input = { paragraph },\n",
    "    };\n",
    "\n",
    "    // Get the embeddings for the current paragraph\n",
    "    var returnValue = openAIClient.GetEmbeddings(embeddingOptions);\n",
    "    float[] embeddingVector = returnValue.Value.Data[0].Embedding.ToArray();\n",
    "    \n",
    "    // Add the paragraph and its corresponding embeddings to the current document\n",
    "    currentDocument[\"id\"] = Guid.NewGuid().ToString();\n",
    "    currentDocument[\"content\"] = paragraph;\n",
    "    currentDocument[\"contentVector\"] = embeddingVector;\n",
    "    inputDocuments.Add(currentDocument);\n",
    "}\n",
    "\n",
    "// Get the embeddings for the first document in the list and pring it.\n",
    "float[] firstDocumentVector = (float[])inputDocuments.First()[\"contentVector\"];\n",
    "string embeddingString = String.Join(\", \", firstDocumentVector);\n",
    "Console.WriteLine(embeddingString);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Vector Index on Azure AI Search\n",
    "\n",
    "Vector search is a method in information retrieval that utilizes numerical representations of content for search applications. In this approach, the content is represented in numeric form, allowing the search engine to identify and match vectors that most closely resemble the query. This method does not rely on exact term matching, as it operates on the principle of similarity between vectors.\n",
    "\n",
    "Recently, Azure AI Search (formerly known as Azure Cognitive Search) has introduced vector search as a new feature. This capability enhances Azure AI Search by enabling the indexing, storage, and retrieval of vector embeddings directly from a search index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget: Azure.Search.Documents, 11.5.1\"\n",
    "#r \"nuget: Azure.Identity, 1.10.4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we're setting up a vector index named 'vectorindex'. This index will consist of three fields:\n",
    "\n",
    "1. **ID:** Serves as a unique identifier for each document.\n",
    "2. **Content:** Contains the original text of each document. It's crucial to store the original text because we cannot reconstruct the original text from its embedding.\n",
    "3. **ContentVector:** Stores the embedding vector generated for each text chunk.\n",
    "\n",
    "We designate the 'Content' field as a SearchableField in anticipation of performing a hybrid search. Hybrid search is an advanced technique that combines traditional text search with vector search in a single query. Text search operates on plain text in 'searchable' and 'filterable' fields, while vector search applies to the content in vector fields.\n",
    "\n",
    "Real-world and benchmark dataset [tests have shown](https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/azure-cognitive-search-outperforming-vector-search-with-hybrid/ba-p/3929167) that hybrid retrieval, which incorporates semantic ranking, significantly enhances search relevance, offering a robust approach to information retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using Azure.Search.Documents;\n",
    "using Azure.Search.Documents.Indexes;\n",
    "using Azure.Search.Documents.Indexes.Models;\n",
    "using Azure.Search.Documents.Models;\n",
    "using Azure;\n",
    "\n",
    "// Define the Azure Search service endpoint and admin key\n",
    "string serviceEndpoint = envVars[\"AZURE_SEARCH_SERVICE_ENDPOINT\"];\n",
    "string searchAdminKey = envVars[\"AZURE_SEARCH_ADMIN_KEY\"];\n",
    "\n",
    "string indexName = \"vectorindex\";\n",
    "var searchCredential = new AzureKeyCredential(searchAdminKey);\n",
    "var indexClient = new SearchIndexClient(new Uri(serviceEndpoint), searchCredential);\n",
    "var searchClient = indexClient.GetSearchClient(indexName);\n",
    "\n",
    "// Define the vector search profile and HNSW configuration. We will use the default values.\n",
    "string vectorSearchProfile = \"my-vector-profile\";\n",
    "string vectorSearchHnswConfig = \"my-hnsw-vector-config\";\n",
    "\n",
    "// Create a new SearchIndex Definition\n",
    "SearchIndex searchIndex = new(indexName)\n",
    "{\n",
    "    VectorSearch = new()\n",
    "    {\n",
    "        Profiles =\n",
    "        {\n",
    "            new VectorSearchProfile(vectorSearchProfile, vectorSearchHnswConfig)\n",
    "        },\n",
    "            Algorithms =\n",
    "        {\n",
    "            new HnswAlgorithmConfiguration(vectorSearchHnswConfig)\n",
    "        }\n",
    "    },\n",
    "    Fields =\n",
    "    {\n",
    "        new SimpleField(\"id\", SearchFieldDataType.String) \n",
    "        { \n",
    "            IsKey = true, \n",
    "            IsFilterable = true, \n",
    "            IsSortable = true\n",
    "        },\n",
    "        new SearchableField(\"content\") \n",
    "        { \n",
    "            IsFilterable = true \n",
    "        },\n",
    "        new SearchField(\"contentVector\", SearchFieldDataType.Collection(SearchFieldDataType.Single))\n",
    "        {\n",
    "            IsSearchable = true,\n",
    "            // Azure OpenAI model, text-embedding-ada-002 with 1,536 dimensions means one document would consume 1,536 floats.\n",
    "            VectorSearchDimensions = 1536,\n",
    "            VectorSearchProfileName = vectorSearchProfile\n",
    "        }\n",
    "    }\n",
    "};\n",
    "\n",
    "indexClient.CreateOrUpdateIndex(searchIndex);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Embeddings to Azure AI Search\n",
    "\n",
    "In this phase, we are uploading both the embeddings and the original text to our index. This operation is flexible and can be repeated as often as necessary, allowing for the continuous integration of new information and data into the index. This adaptability ensures that the index remains up-to-date and reflective of the latest content and insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "await searchClient.IndexDocumentsAsync(IndexDocumentsBatch.Upload(inputDocuments));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing a vector similarity search\n",
    "\n",
    "Now we're moving on to the testing phase. We'll use a sample query to search within our vector database, aiming to find information relevant to the query. This process is a key part of implementing the Retrieval-Augmented Generation (RAG) pipeline. By doing so, we'll be able to enhance our prompt with contextually relevant data, thereby leveraging the full potential of the RAG model to generate more accurate and context-aware responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var query = \"Can you provide the timestamp for the most recent information you have on Azure Functions? Please specify the date and time up to your last update. Give me only the date.\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings transform the prompt into a numerical representation, a process known as feature extraction. This numerical form enables easy comparison and retrieval from a vector database. Crucially, embeddings capture the semantic essence of the prompt, allowing the system to identify relevant information that shares a similar meaning, even if the exact wording of the prompt isn't present in the database.\n",
    "\n",
    "In the following step, we create an embedding for our original prompt to facilitate the retrieval of pertinent information from the vector database. We aim to fetch the top 3 most relevant results, storing them in memory for subsequent use.\n",
    "\n",
    "It's important to note that our approach here is not limited to vector search alone; we are employing a **hybrid search** method. This involves passing the prompt as a 'query' and specifying 'embed' in the 'searchoptions'. Such a setup conducts a vector search on the 'contentVector' field and a text search on the 'content' field, thereby leveraging the strengths of both search methodologies for [more effective and comprehensive retrieval](https://learn.microsoft.com/en-us/azure/search/hybrid-search-overview#how-does-hybrid-search-work)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Generate the embedding for the query  \n",
    "EmbeddingsOptions embeddingOptions = new()\n",
    "{\n",
    "    DeploymentName = \"text-embedding-ada-002\",\n",
    "    Input = { query },\n",
    "};\n",
    "var returnValue = openAIClient.GetEmbeddings(embeddingOptions);\n",
    "float[] queryEmbeddings = returnValue.Value.Data[0].Embedding.ToArray();\n",
    "\n",
    "// Perform the vector similarity search  \n",
    "var searchOptions = new SearchOptions\n",
    "{\n",
    "    VectorSearch = new()\n",
    "    {\n",
    "        Queries = { new VectorizedQuery(queryEmbeddings.ToArray()) { KNearestNeighborsCount = 3, Fields = { \"contentVector\" } } }\n",
    "    },\n",
    "    Size = 3,\n",
    "    Select = { \"content\" },\n",
    "};\n",
    "\n",
    "// Initialize a list to store the search result documents for future RAG use.\n",
    "List<SearchDocument> searchDocuments = new List<SearchDocument>();\n",
    "\n",
    "// Perform the search and get the response\n",
    "SearchResults<SearchDocument> response = await searchClient.SearchAsync<SearchDocument>(query, searchOptions);\n",
    "\n",
    "await foreach (SearchResult<SearchDocument> result in response.GetResultsAsync())\n",
    "{\n",
    "    searchDocuments.Add(result.Document);\n",
    "    Console.WriteLine($\"Score: {result.Score}\\n\");\n",
    "    Console.WriteLine($\"Content: {result.Document[\"content\"]}\\n\");\n",
    "}\n",
    "\n",
    "Console.WriteLine($\"Total Results: {searchDocuments.Count}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrievel Augmented Generation (RAG) - Standard GPT Output\n",
    "\n",
    "In this step, we're conducting a test to assess the baseline performance of the Large Language Model (LLM) without incorporating additional relevant information into the system prompt. This test will provide a standard output from the LLM, serving as a reference point to evaluate the impact and effectiveness of adding contextually relevant data from our vector database in subsequent steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "string chatDeploymentName = envVars[\"OPENAI_CHAT_DEPLOYMENT_NAME\"]; \n",
    "\n",
    "var chatCompletionsOptions = new ChatCompletionsOptions()\n",
    "{\n",
    "    DeploymentName = chatDeploymentName, \n",
    "    Messages =\n",
    "    {\n",
    "        new ChatRequestSystemMessage(\"You are a helpful assistant and always tell the truth. You dont talk much.\"),\n",
    "        new ChatRequestUserMessage(query)\n",
    "    },\n",
    "    MaxTokens = 100\n",
    "};\n",
    "\n",
    "Response<ChatCompletions> response = openAIClient.GetChatCompletions(chatCompletionsOptions);\n",
    "\n",
    "Console.WriteLine(response.Value.Choices[0].Message.Content);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrievel Augmented Generation (RAG) - Augemented GPT Output\n",
    "\n",
    "At this final stage, we are integrating the three embeddings identified as relevant into the system prompt. This integration is a strategic step to enrich the Large Language Model (LLM) with pertinent and current information. By doing so, we enable the LLM to utilize this contextually relevant data when responding to user prompts, thereby enhancing the accuracy, relevance, and overall quality of its responses. This method illustrates the practical application of the Retrieval-Augmented Generation (RAG) approach, demonstrating how external data can significantly improve the model's performance in generating informed and context-aware replies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "string firstDocumentContent = searchDocuments[0][\"content\"].ToString();\n",
    "\n",
    "var chatCompletionsOptions = new ChatCompletionsOptions()\n",
    "{\n",
    "    DeploymentName = chatDeploymentName, \n",
    "    Messages =\n",
    "    {\n",
    "        new ChatRequestSystemMessage($\"You are a helpful assistant and always tell the truth. You dont talk much. Here is what you know : {firstDocumentContent}\"),\n",
    "        new ChatRequestUserMessage(query)\n",
    "    },\n",
    "    MaxTokens = 100\n",
    "};\n",
    "\n",
    "Response<ChatCompletions> response = openAIClient.GetChatCompletions(chatCompletionsOptions);\n",
    "\n",
    "Console.WriteLine(response.Value.Choices[0].Message.Content);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "languageName": "csharp",
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
